import math
import torch
import torch.nn as nn
import torchvision
from torch.autograd import Variable
from . import block as B

####################
# Generator
####################


#class SRResNet(nn.Module):
#    def __init__(self, in_nc, out_nc, nf, nb, upscale=4, norm_type='batch', act_type='relu', \
#            mode='NAC', res_scale=1, upsample_mode='upconv'):
#        super(SRResNet, self).__init__()
#        n_upscale = int(math.log(upscale, 2))
#        if upscale == 3:
#            n_upscale = 1
#
#        fea_conv = B.conv_block(in_nc, nf, kernel_size=3, norm_type=None, act_type=None)
#        resnet_blocks = [B.ResNetBlock(nf, nf, nf, norm_type=norm_type, act_type=act_type,\
#            mode=mode, res_scale=res_scale) for _ in range(nb)]
#        LR_conv = B.conv_block(nf, nf, kernel_size=3, norm_type=norm_type, act_type=None, mode=mode)
#
#        if upsample_mode == 'upconv':
#            upsample_block = B.upconv_blcok
#        elif upsample_mode == 'pixelshuffle':
#            upsample_block = B.pixelshuffle_block
#        else:
#            raise NotImplementedError('upsample mode [%s] is not found' % upsample_mode)
#        if upscale == 3:
#            upsampler = upsample_block(nf, nf, 3, act_type=act_type)
#        else:
#            upsampler = [upsample_block(nf, nf, act_type=act_type) for _ in range(n_upscale)]
#        HR_conv0 = B.conv_block(nf, nf, kernel_size=3, norm_type=None, act_type=act_type)
#        HR_conv1 = B.conv_block(nf, out_nc, kernel_size=3, norm_type=None, act_type=None)
#
#        self.model = B.sequential(fea_conv, B.ShortcutBlock(B.sequential(*resnet_blocks, LR_conv)),\
#            *upsampler, HR_conv0, HR_conv1)
#
#    def forward(self, x):
#        x = self.model(x)
#        return x
#
#
#####################
## Discriminator
#####################
#
#
## VGG style Discriminator with input size 128*128
#class Discriminaotr_VGG_128(nn.Module):
#    def __init__(self, in_nc, base_nf, norm_type='batch', act_type='leakyrelu', mode='CNA'):
#        super(Discriminaotr_VGG_128, self).__init__()
#        # features
#        # hxw, c
#        # 128, 64
#        conv0 = B.conv_block(in_nc, base_nf, kernel_size=3, norm_type=None, act_type=act_type, \
#            mode=mode)
#        conv1 = B.conv_block(base_nf, base_nf, kernel_size=4, stride=2, norm_type=norm_type, \
#            act_type=act_type, mode=mode)
#        # 64, 64
#        conv2 = B.conv_block(base_nf, base_nf*2, kernel_size=3, stride=1, norm_type=norm_type, \
#            act_type=act_type, mode=mode)
#        conv3 = B.conv_block(base_nf*2, base_nf*2, kernel_size=4, stride=2, norm_type=norm_type, \
#            act_type=act_type, mode=mode)
#        # 32, 128
#        conv4 = B.conv_block(base_nf*2, base_nf*4, kernel_size=3, stride=1, norm_type=norm_type, \
#            act_type=act_type, mode=mode)
#        conv5 = B.conv_block(base_nf*4, base_nf*4, kernel_size=4, stride=2, norm_type=norm_type, \
#            act_type=act_type, mode=mode)
#        # 16, 256
#        conv6 = B.conv_block(base_nf*4, base_nf*8, kernel_size=3, stride=1, norm_type=norm_type, \
#            act_type=act_type, mode=mode)
#        conv7 = B.conv_block(base_nf*8, base_nf*8, kernel_size=4, stride=2, norm_type=norm_type, \
#            act_type=act_type, mode=mode)
#        # 8, 512
#        conv8 = B.conv_block(base_nf*8, base_nf*8, kernel_size=3, stride=1, norm_type=norm_type, \
#            act_type=act_type, mode=mode)
#        conv9 = B.conv_block(base_nf*8, base_nf*8, kernel_size=4, stride=2, norm_type=norm_type, \
#            act_type=act_type, mode=mode)
#        # 4, 512
#        self.features = B.sequential(conv0, conv1, conv2, conv3, conv4, conv5, conv6, conv7, conv8,\
#            conv9)
#
#        # classifier
#        self.classifier = nn.Sequential(
#            nn.Linear(512*4*4, 100),
#            nn.LeakyReLU(0.2, True),
#            nn.Linear(100, 1)
#        )
#
#    def forward(self, x):
#        x = self.features(x)
#        x = x.view(x.size(0), -1)
#        x = self.classifier(x)
#        return x


####################
# Perceptual Network
####################


# Assume input range is [0, 1]
class VGGFeatureExtractor(nn.Module):
    def __init__(self,
                 feature_layer=34,
                 use_bn=False,
                 use_input_norm=True,
                 tensor=torch.FloatTensor):
        super(VGGFeatureExtractor, self).__init__()
        if use_bn:
            model = torchvision.models.vgg19_bn(pretrained=True)
        else:
            model = torchvision.models.vgg19(pretrained=True)
        self.use_input_norm = use_input_norm
        if self.use_input_norm:
            mean = Variable(tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1), requires_grad=False)
            # [0.485-1, 0.456-1, 0.406-1] if input in range [-1,1]
            std = Variable(tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1), requires_grad=False)
            # [0.229*2, 0.224*2, 0.225*2] if input in range [-1,1]
            self.register_buffer('mean', mean)
            self.register_buffer('std', std)
        self.features = nn.Sequential(*list(model.features.children())[:(feature_layer + 1)])
        # No need to BP to variable
        for k, v in self.features.named_parameters():
            v.requires_grad = False

    def forward(self, x):
        if self.use_input_norm:
            x = (x - self.mean) / self.std
        output = self.features(x)
        return output
